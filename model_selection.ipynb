{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing and selection \n",
    "> In this notebook we test various RNN models to predict a company's following day closing stock price.\n",
    "At the end we select one model to train all of our stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1) Import data_manager module and other libraries\n",
    "    \n",
    "     The data_manager module has helper classes and methods for working with our stock data.\n",
    "     \n",
    "   > The module has the following class that we will use in this notebook:\n",
    "\n",
    "   > ###### SimpleSequence -\n",
    "   Sequence class that creates input (x) and target (y) for RNN training or prediction,\n",
    "        based on given window size (x) and target (y) lengths.\n",
    "        The sequence is created from end of day normalized adjusted close stock pricess.\n",
    "\n",
    "> ###### MultiSequence -\n",
    "   Sequence class that creates input (x) and target (y) for RNN training or prediction,\n",
    "        based on given window size (x) and target (y) lengths.\n",
    "        The sequence is created from three features i) end of day normalized adjusted close stock pricess\n",
    "        ii) log normal returns and iii) normalized MFI index.\n",
    "        \n",
    " We will also use a few other helper methods such as  `'companies()'` and `'split_data()'`  methods from data_manager module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport data_manager\n",
    "%autoreload 1\n",
    "\n",
    "from data_manager import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2) Import company list\n",
    "> Here we read a csv file and import a list of company trade symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock ticker selected for testing: ['Snap', 'SNAP', 'Social']\n"
     ]
    }
   ],
   "source": [
    "#read list of companies from csv file\n",
    "stocks = companies()\n",
    "tickers = stocks.values.tolist()\n",
    "\n",
    "#Select stock to perform tests\n",
    "ticker = tickers[0]\n",
    "\n",
    "print(\"Stock ticker selected for testing: {}\".format(ticker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) RNN Models\n",
    "> In this step we select four RNN models that we will train and evaluate how accurate they are on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "def fixed_model(X,y, learn_rate):\n",
    "    \"\"\"\n",
    "    RNN model with one LSTM layer (output of 5) and 1 fully connected output tanh layer    \n",
    "    \n",
    "    Parameter\n",
    "    -----------\n",
    "    X: numpy array\n",
    "              input sequence data.\n",
    "    \n",
    "    y: numpy array\n",
    "              target sequence data.\n",
    "    \n",
    "    learn_rate: float\n",
    "            Neural network learning rate.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(5,input_shape=(X.shape[1:])))\n",
    "    model.add(Dense(y.shape[1], activation='tanh'))\n",
    "      \n",
    "    # compile the model\n",
    "    optimizer = RMSprop(lr=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "def dynamic_model(X,y, learn_rate):\n",
    "    \"\"\"\n",
    "    RNN model with one LSTM layer (output based on input sequence length) and 1 fully connected output tanh layer    \n",
    "    \n",
    "    Parameter\n",
    "    -----------\n",
    "    X: numpy array\n",
    "              input sequence data.\n",
    "    \n",
    "    y: numpy array\n",
    "              target sequence data.\n",
    "    \n",
    "    learn_rate: float\n",
    "            Neural network learning rate.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(X.shape[1],input_shape=(X.shape[1:])))\n",
    "    model.add(Dense(y.shape[1], activation='tanh'))\n",
    "      \n",
    "    # compile the model\n",
    "    optimizer = RMSprop(lr=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "def bidirectional_model(X,y, learn_rate):\n",
    "    \"\"\"\n",
    "    Bidirectional RNN model with one LSTM layer (output based on input sequence length), \n",
    "    one fully connected layer (output based on input sequence length) \n",
    "    and 1 fully connected output tanh layer    \n",
    "    \n",
    "    Parameter\n",
    "    -----------\n",
    "    X: numpy array\n",
    "              input sequence data.\n",
    "    \n",
    "    y: numpy array\n",
    "              target sequence data.\n",
    "    \n",
    "    learn_rate: float\n",
    "            Neural network learning rate.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(X.shape[1],return_sequences=False), input_shape=(X.shape[1:])))\n",
    "    model.add(Dense(X.shape[1]))\n",
    "    model.add(Dense(y.shape[1], activation='tanh'))\n",
    "      \n",
    "    # compile the model\n",
    "    optimizer = RMSprop(lr=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "def stacked_model(X,y, learn_rate):\n",
    "    \"\"\"\n",
    "    Stacked RNN model with two LSTM layers and 1 fully connected output tanh layer.\n",
    "    First LSTM layer has output of 10 and the second has 5.\n",
    "    \n",
    "    Parameter\n",
    "    -----------\n",
    "    X: numpy array\n",
    "              input sequence data.\n",
    "    \n",
    "    y: numpy array\n",
    "              target sequence data.\n",
    "    \n",
    "    learn_rate: float\n",
    "            Neural network learning rate.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10,return_sequences=True, input_shape=(X.shape[1:])))\n",
    "    model.add(LSTM(5))\n",
    "    model.add(Dense(y.shape[1], activation='tanh'))\n",
    "      \n",
    "    # compile the model\n",
    "    optimizer = RMSprop(lr=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "#Create list of our models for use by the testing function.\n",
    "models =[]\n",
    "models.append((\"Fixed\",fixed_model))\n",
    "models.append((\"Dynamic\",dynamic_model))\n",
    "models.append((\"Bidirectional\",bidirectional_model))\n",
    "models.append((\"Stacked\",stacked_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Testing function\n",
    "> Here we define a `'test_model()'` function to evaluate each RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def test_model(ticker,epochs,models,seq,window_sizes):\n",
    "    \"\"\"\n",
    "    Function to test the performance of our RNN models     \n",
    "    \n",
    "    Parameter\n",
    "    -----------\n",
    "    stock:  str\n",
    "            Compnay trade ticker.\n",
    "    \n",
    "    epoch:  int\n",
    "            Number of epochs to train RNN.\n",
    "    \n",
    "    models: list of RNN model functions  \n",
    "            Each item is a tuple where 1st item is string name of model\n",
    "            and the 2nd is a model function that accepts X,y and learn_rate paramenter.\n",
    "    \n",
    "    seq:    Data sequence object\n",
    "            Object that has input X and target y sequence data.\n",
    "    \n",
    "    window_sizes: list\n",
    "                  A list of different window size (sequence length X input) to test.  \n",
    "    Returns:\n",
    "    ---------\n",
    "    Returns an ordered dictionary with the result of the model testing as six list;\n",
    "    'Window Size', 'Sequence Name','Model Name',\n",
    "    'Training Error','Testing Error' and 'Param Count'.\n",
    "    \"\"\"\n",
    "    #test result data\n",
    "    sizes = []\n",
    "    #seq_name = []\n",
    "    model_name = []\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    param_count = []\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        print(\"\\nWindow size: {}\".format(window_size))\n",
    "        print('----------------')\n",
    "        for model_item in models:\n",
    "            seq_obj = seq[1](ticker,window_size,1)\n",
    "            X_train,y_train,X_test,y_test = split_data(seq_obj)\n",
    "            model = model_item[1](X_train,y_train,0.001)\n",
    "            \n",
    "            # fit model!\n",
    "            model.fit(X_train, y_train, epochs=epochs, batch_size=50, verbose=0)\n",
    "\n",
    "            # print out training and testing errors\n",
    "            training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "            testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "            msg = \" > Model: {0:<15} Param count: {1:} \\tTraining error: {2:.4f}\\tTesting error: {3:.4f}\"\n",
    "            print(msg.format(model_item[0],model.count_params(),training_error,testing_error))\n",
    "\n",
    "            #update result variables\n",
    "            param_count.append(model.count_params())\n",
    "            sizes.append(window_size)\n",
    "            #seq_name.append(seq[0])\n",
    "            model_name.append(model_item[0])\n",
    "            train_errors.append(float(\"{0:.4f}\".format(training_error)))\n",
    "            test_errors.append(float(\"{0:.4f}\".format( testing_error)))\n",
    "\n",
    "    table= OrderedDict()\n",
    "    table['Window Size'] = sizes\n",
    "    table['Sequence Name'] =  [seq[0] for _ in range(len(sizes))]\n",
    "    table['Model Name'] = model_name\n",
    "    table['Ticker'] = [ticker for _ in range(len(sizes))]\n",
    "    table['Training Error'] = train_errors\n",
    "    table['Testing Error'] = test_errors\n",
    "    table['Param Count'] = param_count\n",
    "        \n",
    "    return table\n",
    "\n",
    "\n",
    "def update_test_table(*argv):\n",
    "    \"\"\"Updates a model testing table \n",
    "    \"\"\"\n",
    "    file_path = \"./data/model_test.csv\"\n",
    "    \n",
    "    table = pd.read_csv(file_path)\n",
    "    tickers = set( table['Ticker'].values.tolist())\n",
    "    \n",
    "    for item in argv:\n",
    "\n",
    "        #first check if already exist \n",
    "        check = item['Ticker'][0]\n",
    "        if check in tickers:\n",
    "            #drop items\n",
    "            idx = table[(table['Ticker']== check)  &  (table['Sequence Name']== item['Sequence Name'][0])].index\n",
    "            table =  table.drop(idx)\n",
    "\n",
    "        #append current test\n",
    "        table = table.append(pd.DataFrame(item))\n",
    "\n",
    "    table = table.reset_index(drop=True)\n",
    "    table.to_csv(file_path, index = False)\n",
    "\n",
    "def get_test_table():\n",
    "    \"\"\"Get testing table and returned as DataFrame\n",
    "    \"\"\"\n",
    "    file_path = \"./data/model_test.csv\"\n",
    "    return pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Perform model testing\n",
    "> We test each model using a one feature input sequence and a three feature  input sequence of different sequence size or window size.\n",
    "\n",
    "> * The first test uses the `'SimpleSequence()'` class from the `data_manager` to evaluate how well it performs with the four RNN\n",
    "models.  The `'SimpleSequence()'` is a one feature sequence based on normalized stock prices.   \n",
    "\n",
    "\n",
    "> * In the second test we use the `'MultiSequence()'` class from the `data_manager`.  The `'MultiSequence()'` is a three normalize feature sequence; closing stock prices, log normal daily returns and MFI index.\n",
    "\n",
    "\n",
    "> * The goals of the testing are to 1) decide which input sequence is better, 2) select the best performing window size  and 3) choose the best RNN model that best captures the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "#Model testing variables\n",
    "epochs =100\n",
    "window_sizes =[5,7,10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Simple Sequence Model Test for ['Snap', 'SNAP', 'Social'] ***\n",
      "=============================================\n",
      "\n",
      "Window size: 5\n",
      "----------------\n",
      "Unexpected error for symbol ['Snap', 'SNAP', 'Social']:<class 'FileNotFoundError'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SimpleSequence' object has no attribute '_SequenceBase__data_normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ce89e43db246>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mseq_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Simple'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSimpleSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtest_1\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mupdate_test_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-0464e0a3c766>\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(ticker, epochs, models, seq, window_sizes)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'----------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodel_item\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mseq_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_item\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Tensor\\Stock_Analysis\\stock_projections\\data_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, symbol, window_size, target_length)\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[0mSequenceBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__sequence_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__sequence_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Tensor\\Stock_Analysis\\stock_projections\\data_manager.py\u001b[0m in \u001b[0;36m__sequence_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \"\"\"\n\u001b[0;32m    481\u001b[0m             \u001b[1;31m#normalized values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'normal_close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Tensor\\Stock_Analysis\\stock_projections\\data_manager.py\u001b[0m in \u001b[0;36mdata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;34m\"\"\" Get the trade data as a DataFrame \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data_normal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SimpleSequence' object has no attribute '_SequenceBase__data_normal'"
     ]
    }
   ],
   "source": [
    "print(\"*** Simple Sequence Model Test for {} ***\".format(ticker))\n",
    "print(\"=\" * 45)\n",
    "\n",
    "seq_name = ('Simple',SimpleSequence)\n",
    "\n",
    "test_1  = test_model(ticker,epochs,models,seq_name,window_sizes)\n",
    "update_test_table(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** Multi Sequence Model Test for {} ***\".format(ticker))\n",
    "print(\"=\" * 45)\n",
    "\n",
    "seq_name = ('Multi',MultiSequence)\n",
    "\n",
    "test_2  = test_model(ticker,epochs,models,seq_name,window_sizes)\n",
    "update_test_table(test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Evaluate and summarize test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update and get model testing table\n",
    "#table = update_test_table(test_1,test_2)\n",
    "\n",
    "table = get_test_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize model testing by sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(table, values=['Training Error','Testing Error'], index=['Sequence Name']\n",
    "               ,aggfunc={'Training Error':np.mean, 'Testing Error':np.mean} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize model testing by Ticker symbol and window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(table, values=['Training Error','Testing Error'], index=['Ticker','Window Size']\n",
    "               ,aggfunc={'Training Error':np.mean, 'Testing Error':np.mean} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize model testing by sequence and window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(table, values=['Training Error','Testing Error'], index=['Sequence Name','Window Size']\n",
    "               ,aggfunc={'Training Error':np.mean, 'Testing Error':np.mean} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize model testing by RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(table, values=['Training Error','Testing Error'], index=['Model Name']\n",
    "               ,aggfunc={'Training Error':np.mean, 'Testing Error':np.mean} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize model testing by sequence and RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(table, values=['Training Error','Testing Error'], index=['Sequence Name' ,'Model Name']\n",
    "               ,aggfunc={'Training Error':np.mean, 'Testing Error':np.mean} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize model testing by model parameter count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(table, values='Param Count', index=['Sequence Name','Model Name'], columns=['Window Size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing observations\n",
    "* The multi sequence input performed better than the simple sequence input.  This is evident since the training and testing errors are both smaller for the multi sequence.\n",
    "\n",
    "\n",
    "* Not one particular window size captured the target variable the best.\n",
    "\n",
    "\n",
    "* The dynamic and the bidirectional models performed the best as they have smallest training and testing errors.\n",
    "\n",
    "\n",
    "* The model parameter count between the different models is negligible and we can perform our training on a cpu.\n",
    "\n",
    "\n",
    "* All the models can probably get an improvement by adding a dropout layer since the testing error was larger than the training in every case.  Further testing is needed to check if a higher epoch count can decrease the variance between training and testing error.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and model selection \n",
    " Based on the model testing results we arrive at the following conclusions:\n",
    "* We will use the multi sequence input since it better captures the target variable.\n",
    "\n",
    "\n",
    "* Since no window size outperformed we will pass a list of Window sizes to our final model and return the best performing model.\n",
    "\n",
    "\n",
    "* We choose the bidirectional model since its the best performing model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Live model testing\n",
    "* In in this section we define a live model which is the bidirectional model but with a dropout layer.\n",
    "\n",
    "\n",
    "* We test the live model with different dropout and learning rates to uncover the optiomal rates.\n",
    "\n",
    "\n",
    "* We use a window size of 10 at this point since we are only interested in finding the best learnng and drop out rates.\n",
    "\n",
    "\n",
    "* We also perform a test to gage the optimal number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_model(X,y, learn_rate,dropout):\n",
    "    \"\"\"\n",
    "     RNN model with following layers:\n",
    "        1) one LSTM layer (output size based on X input sequence length)\n",
    "        2) Dropout (based on given dropout rate) \n",
    "        3) fully connected tanh output layer of 1\n",
    "    \n",
    "    Parameter\n",
    "    -----------\n",
    "    X: numpy array\n",
    "              input sequence data.\n",
    "    \n",
    "    y: numpy array\n",
    "              target sequence data.\n",
    "    \n",
    "    learn_rate: float\n",
    "            Neural network learning rate.\n",
    "            \n",
    "    dropout: float\n",
    "            Dropout rate.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(X.shape[1],return_sequences=False), input_shape=(X.shape[1:])))\n",
    "    model.add(Dense(X.shape[1]))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(y.shape[1], activation='tanh'))\n",
    "    \n",
    "    # compile the model\n",
    "    optimizer = RMSprop(lr=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "window_size = 10\n",
    "dropouts =  [0.0,0.25,0.4,0.50]\n",
    "learn_rates = [0.01,0.001,0.0001]\n",
    "batch_size = 50\n",
    "epochs_live = 100\n",
    "\n",
    "def test_live(X_train,y_train,X_test,y_test):\n",
    "    best_model = None\n",
    "    lowest_test_error = 2.0\n",
    "    best_learn_rate = 0.0\n",
    "    best_dropout_rate = 0.0\n",
    "    for rate in learn_rates:\n",
    "        print(\"\\nLearn rate: {0:.4f}\".format(rate))\n",
    "        print('---------------------')\n",
    "        lengend = []\n",
    "        for dropout in dropouts:\n",
    "            model = live_model(X_train,y_train,rate,dropout)\n",
    "            history = model.fit(X_train, y_train, epochs=epochs_live, batch_size=batch_size, verbose=0)\n",
    "\n",
    "            # print out training and testing errors\n",
    "            training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "            testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "            msg = \" > Dropout: {0:.2f} Training error: {1:.4f}\\tTesting error: {2:.4f}\"\n",
    "            print(msg.format(dropout, training_error,testing_error))\n",
    "            \n",
    "            #check if test error\n",
    "            if lowest_test_error > testing_error:\n",
    "                best_model = model\n",
    "                lowest_test_error = testing_error\n",
    "                best_learn_rate = rate\n",
    "                best_dropout_rate = dropout\n",
    "                \n",
    "            #plot loss function\n",
    "            plt.plot(history.history['loss'])\n",
    "            lengend.append(\"Drop {0:.4f}\".format(dropout)) \n",
    "    \n",
    "        plt.title(\"Learn rate {0:.4f}\".format(rate))\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('loss')\n",
    "        plt.legend(lengend,loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.show()\n",
    "    \n",
    "    return (best_model,lowest_test_error,best_learn_rate,best_dropout_rate)\n",
    "\n",
    "\n",
    "seq_obj = MultiSequence(ticker,window_size,1)\n",
    "dataset = seq_obj.original_data\n",
    "X_train,y_train,X_test,y_test = split_data(seq_obj)\n",
    "\n",
    "print(\"*** Live Model Testing ***\")\n",
    "print(\"=\" * 40)        \n",
    "results = test_live(X_train,y_train,X_test,y_test)\n",
    "\n",
    "\n",
    "print(\"*** Best Live Model Summary***\")\n",
    "print(\"=\" * 40) \n",
    "print(\"Testing error: {0:.4f}\".format(results[1]))\n",
    "print(\"Best learning rate: {}\".format(results[2]))\n",
    "print(\"Best dropout rate: {}\".format(results[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn rate and dropout testing results\n",
    "> * Looking at testing results we can see that learn of 0.01 and 0.001 performed better than 0.0001.\n",
    "> * The dropout rates of 0.0, 0.25 and 0.40 had the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch testing\n",
    "> We perform a test to try and find the optimal epoch count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get fourt tickers to perform out epoch test\n",
    "ticker_epochs = [tickers[i][1] for i in range(4)]\n",
    "\n",
    "window_size = 10\n",
    "dropout_rate = 0.25\n",
    "epochs_list = [50,100,200,500,1000]\n",
    "batch_size = 50\n",
    "learn_rate = 0.001\n",
    "\n",
    "def test_epochs():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    for symbol in ticker_epochs:\n",
    "        print(\"\\nSymbol: {}\".format(symbol))\n",
    "        print('---------------------')\n",
    "        seq_obj = MultiSequence(symbol,window_size,1)\n",
    "        X_train,y_train,X_test,y_test = split_data(seq_obj)\n",
    "        lowest_test_error = 2.0\n",
    "        best_epoch = 0\n",
    "        for epoch in epochs_list:\n",
    "            model = live_model(X_train,y_train,learn_rate,dropout_rate)\n",
    "            model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "            # print out training and testing errors\n",
    "            training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "            testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "            msg = \" > Epoch: {0:} \\tTraining error: {1:.4f}\\tTesting error: {2:.4f}\"\n",
    "            print(msg.format(epoch, training_error,testing_error))\n",
    "\n",
    "            if lowest_test_error > testing_error:\n",
    "                lowest_test_error = testing_error\n",
    "                best_epoch = epoch\n",
    "        \n",
    "        #print best epoch for symbol\n",
    "        print(\" ==> Best epoch {0:} with testing error of {1:.4f}\".format(best_epoch,lowest_test_error))\n",
    "\n",
    "print(\"*** Epoch Model Testing ***\")\n",
    "print(\"=\" * 40)        \n",
    "test_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch testing conclusion\n",
    "> Our epoch testing finds that there is no optimal epoch count but that we should try 100 and 200 and then return the model that performs the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model selection\n",
    "\n",
    "> * Here we put together everything we learn from our testing to select model for a given ticker.\n",
    "\n",
    "\n",
    "> * To select the best model for a ticker we define a function that accepts a list of window sizes, drop out rates, learn rates\n",
    "and epoch.  \n",
    "\n",
    "\n",
    "> * We graph the model peformance versus original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ticker = tickers[0]\n",
    "window_sizes = [5,7,10]\n",
    "dropouts =  [0.0,0.25,0.4]\n",
    "learn_rates = [0.01,0.001]\n",
    "epochs = [100,200,500]\n",
    "batch_size = 50\n",
    "\n",
    "def best_model(ticker, window_sizes, learn_rates, dropouts, epochs, batch_size):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    #our best model variables\n",
    "    best_model = None\n",
    "    lowest_test_error = 2.0\n",
    "    best_training_error =0.0\n",
    "    best_learn_rate = 0.0\n",
    "    best_dropout_rate = 0.0\n",
    "    best_epoch = 0\n",
    "    best_window_size = 0\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    for window_size in window_sizes:\n",
    "        print(\"\\nWindow size: {}\".format(window_size))\n",
    "        print('---------------------')\n",
    "        \n",
    "        #prepare our sequence data\n",
    "        seq_obj = MultiSequence(ticker,window_size,1)\n",
    "        X_train,y_train,X_test,y_test = split_data(seq_obj)    \n",
    "    \n",
    "        for rate in learn_rates:\n",
    "            for dropout in dropouts:\n",
    "                for epoch in epochs:\n",
    "                    model = live_model(X_train,y_train,rate,dropout)\n",
    "                    model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "                    # print out training and testing errors\n",
    "                    training_error = model.evaluate(X_train, y_train, verbose=0)\n",
    "                    testing_error = model.evaluate(X_test, y_test, verbose=0)\n",
    "                    msg = \" > Learn rate: {0:.4f} Dropout: {1:.2f}\"\n",
    "                    msg += \" Epoch: {2:} Training error: {3:.4f} Testing error: {4:.4f}\"\n",
    "                    msg = str(counter) + \"   \" +msg.format(rate,dropout, epoch, training_error, testing_error)\n",
    "                    print(msg)\n",
    "\n",
    "                    #check if test error \n",
    "                    if lowest_test_error > testing_error:\n",
    "                        best_model = model\n",
    "                        lowest_test_error = testing_error\n",
    "                        best_learn_rate = rate\n",
    "                        best_dropout_rate = dropout\n",
    "                        best_epoch = epoch\n",
    "                        best_training_error = training_error \n",
    "                        best_window_size = window_size\n",
    "                    \n",
    "                    #increase our print counter\n",
    "                    counter += 1\n",
    "                        \n",
    "    best_dict ={}\n",
    "    best_dict[\"ticker\"] = ticker\n",
    "    best_dict[\"model\"] = best_model\n",
    "    best_dict[\"test_error\"] =   \"{0:.4f}\".format(lowest_test_error) \n",
    "    best_dict[\"learn_rate\"] = best_learn_rate\n",
    "    best_dict[\"dropout\"] = best_dropout_rate\n",
    "    best_dict[\"epoch\"] = best_epoch\n",
    "    best_dict[\"train_error\"] =  \"{0:.4f}\".format(best_training_error)  \n",
    "    best_dict[\"window_size\"] = best_window_size\n",
    "    \n",
    "    return best_dict\n",
    "\n",
    "\n",
    "print(\"*** Best Model Selection for {} ***\".format(ticker))\n",
    "print(\"=\" * 40)      \n",
    "results = best_model(ticker, window_sizes, learn_rates, dropouts, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** Best Model Selected Summary for {} ***\".format(results[\"ticker\"]))\n",
    "print(\"=\" * 40) \n",
    "\n",
    "print(\"Window size: {}\".format(results[\"window_size\"]))\n",
    "print(\"Train error: {}\".format(results[\"train_error\"]))\n",
    "print(\"Testing error: {}\".format(results[\"test_error\"]))\n",
    "print(\"Learning rate: {}\".format(results[\"learn_rate\"]))\n",
    "print(\"Dropout rate: {}\".format(results[\"dropout\"]))\n",
    "print(\"Epochs: {}\".format(results[\"epoch\"]))\n",
    "\n",
    "seq_obj = MultiSequence(results[\"ticker\"],results[\"window_size\"],1)\n",
    "dataset = seq_obj.original_data\n",
    "X_train,y_train,X_test,y_test = split_data(seq_obj)\n",
    "\n",
    "graph_prediction(results[\"model\"], X_train,X_test,dataset,results[\"window_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
